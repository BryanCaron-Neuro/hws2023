{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigBrain data processing with CBRAIN and DataLad\n",
    "\n",
    "This tutorial introduces several infrastructure tools used in HIBALL:\n",
    "* <a href=\"#part1\">Part I</a>: DataLad and Boutiques, to access and process BigBrain data through uniform command-line interfaces\n",
    "* <a href=\"#part2\">Part II</a>: CBRAIN, to process BigBrain data on HPC clusters through a web portal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4JoP2Vl8AkC"
   },
   "source": [
    "<div id=\"part1\"/>\n",
    "\n",
    "\n",
    "## Part I: accessing and reusing BigBrain data with DataLad and Boutiques\n",
    "\n",
    "\n",
    "This part of the tutorial will walk you through the following steps:\n",
    "1. <a href=\"#finding\">Finding BigBrain datasets in DataLad</a>\n",
    "2. <a href=\"#installing\">Installing and downloading BigBrain datasets</a>\n",
    "3. <a href=\"#processing\">Processing BigBrain datasets with Boutiques</a>\n",
    "4. <a href=\"#adding\">Uploading derived data to DataLad</a>\n",
    "\n",
    "The main tools and platforms involved in this tutorial are [DataLad](https://www.datalad.org), [Boutiques](http://boutiques.github.io), and the [Canadian Open Neuroscience Platform](http://portal.conp.ca). Please refer to the documentation of these tools for additional information.\n",
    "\n",
    "This tutorial notebook is available on Google Colab and can be done entirely online, without the need for any local software installation. Familiarity with Linux command lines is recommended but not required.\n",
    "\n",
    "Alternately, if you are familiar with the [Docker](http://docker.io) system and want to run the tutorial on your own computer, you can run all the commands of this tutorial in Docker image `glatard/hws`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-_GOTIE8AkG"
   },
   "source": [
    "### Software installation\n",
    "\n",
    "The following script installs the required software in the Google Colab environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvZyaYkm8AkH"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/glatard/hws.git && (cd hws && ./install.sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFiSGbPm8AkJ"
   },
   "source": [
    "<div id=\"finding\"/>\n",
    "\n",
    "\n",
    "### Finding BigBrain datasets in DataLad\n",
    "\n",
    "One of our goals in [HIBALL](https://bigbrainproject.org/hiball.html) is to distribute BigBrain datasets through the uniform interface provided by DataLad. In this part of the tutorial, we will demonstrate how BigBrain data can be downloaded and manipulated using DataLad. A complete introduction to DataLad, including detailed tutorials, is available in the [DataLad handbook](http://handbook.datalad.org/en/latest/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnXjeYIb8AkL"
   },
   "source": [
    "BigBrain DataLad datasets are available through the web portal of the Canadian Open Neuroscience Platform, available at http://portal.conp.ca. They can be found by entering \"BigBrain\" in the search field:\n",
    "\n",
    "![screenshot](figures/search_data.png)\n",
    "\n",
    "https://portal.conp.ca/search?search=bigbrain&sortKey=conpStatus&sortComparitor=asc&page=1&max_per_page=10&cursor=0&limit=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qR4k7tRA8AkM"
   },
   "source": [
    "<div id=\"installing\"/>\n",
    "\n",
    "### Installing and downloading BigBrain datasets\n",
    "\n",
    "Once a dataset is identified, instructions on how to download it using DataLad are available in the corresponding dataset page in the CONP portal:\n",
    "\n",
    "![screenshot](figures/download_instructions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x86lOwzK8AkN"
   },
   "source": [
    "The next steps will go through these instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9fV1Xhb8AkO"
   },
   "source": [
    "#### Dataset installation\n",
    "\n",
    "First, the CONP dataset should be installed to your local machine using `datalad install`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K_X8XJAF8AkP"
   },
   "outputs": [],
   "source": [
    "!datalad install https://github.com/CONP-PCNO/conp-dataset.git\n",
    "%cd conp-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QtNMNcu8AkR"
   },
   "source": [
    "The CONP DataLad dataset contains many datasets, located under `projects`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I297kwAO8AkS"
   },
   "outputs": [],
   "source": [
    "!ls projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nw6WfAX78Akw"
   },
   "source": [
    "The specific BigBrain dataset of interest in this tutorial can be installed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5nYYiq18Akx"
   },
   "outputs": [],
   "source": [
    "!datalad install projects/BigBrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CV6gx-hz8Akz"
   },
   "source": [
    "Importantly, this step does not download the data. Instead, it installs a set of links that could be downloaded at a later stage. Feel free to install any other dataset you might be interested in, this won't involve long transfer times!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztEJeLd18Ak1"
   },
   "source": [
    "This dataset contains the 40$\\mu$m BigBrain blocks, in the Nifti and MINC formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bA4bqIvB8Ak1"
   },
   "outputs": [],
   "source": [
    "!ls projects/BigBrain/3D_Blocks/40um/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4zoajHz8Ak3"
   },
   "source": [
    "It also contains reconstructed 3D volumes at various resolutions and in various spaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zCdivYIO8Ak9"
   },
   "outputs": [],
   "source": [
    "!ls projects/BigBrain/3D_Volumes/*/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxgom8S18Ak_"
   },
   "source": [
    "#### Data download\n",
    "\n",
    "The actual data can be downloaded on demand, using `datalad get`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zihDrQ9v8Ak_"
   },
   "outputs": [],
   "source": [
    "!datalad get projects/BigBrain/3D_Volumes/MNI-ICBM152_Space/nii/full8_400um_2009b_sym.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqW82R3e8Ak_"
   },
   "source": [
    "The data is now available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ai6UI9xn8AlA",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nibabel as nib\n",
    "import nilearn.plotting as nilp\n",
    "im1 = nib.load('projects/BigBrain/3D_Volumes/MNI-ICBM152_Space/nii/full8_400um_2009b_sym.nii.gz')\n",
    "nilp.view_img(im1.slicer[100:200,100:200,100:200], bg_img=None, cmap='gray', resampling_interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"processing\"/>\n",
    "\n",
    "\n",
    "### Processing BigBrain datasets with Boutiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSO1p9Mk8AlB",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a href=\"https://docs.google.com/presentation/d/1w9SC6IMxhTneR1Mac3-RoF8_ps84XDMIexiwpU_0ERo\" target=\"_blank\">\n",
    "    <img src=\"./figures/Boutiques.svg/\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does Boutiques facilitate the processing of BigBrain ? \n",
    "\n",
    "Boutiques wraps around command-line tools to facilitate their porting to different environments.\n",
    "For instance, locally you might be processing BigBrain using an FSL [Docker](https://www.docker.com/)\n",
    "container. However, for security reasons, HPC environments use [Singularity](https://singularity.lbl.gov/)\n",
    "for containerization. While their command-lines are similar, you'd would still have to alter your script to\n",
    "enable use of both.\n",
    "\n",
    "Boutiques abstracts the interfacing with container technologies entirely. All you need is Boutiques installed\n",
    "(via `pip install boutiques`), a Boutiques tool, and an invocation file and you're ready to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-cWnx0w8AlB"
   },
   "source": [
    "#### What makes a tool a Boutiques tool?\n",
    "\n",
    "A Boutiques tool is any command line tool that is described within a descriptor file following the Boutiques json schema.\n",
    "\n",
    "The content of a Boutiques descriptor can be seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!bosh pprint zenodo.4472771"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETG3__kC8AlC"
   },
   "source": [
    "#### Steps to process data with Boutiques\n",
    "\n",
    "1. `bosh search` your desired tool\n",
    "2. use `bosh example` as a guide for creating a valid invocation for the tool\n",
    "3. Launch the tool with the command `bosh exec launch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-40cGmaM8AlH"
   },
   "source": [
    "#### BoSh search\n",
    "\n",
    "To facilitate search of the available tools published to Zenodo, a search functionality is built into the the **Bo**utiques **Sh**ell (bosh) command line interface.\n",
    "\n",
    "Let's take a look at what are the top 10 most pulled descriptors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uN3Zj2qk8AlH"
   },
   "outputs": [],
   "source": [
    "!bosh search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2Bd5Ys_8AlI"
   },
   "source": [
    "If we have a tool in mind, we can specify the name of the tool within our query to return descriptors with a matching name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "REVSaUJr8AlJ"
   },
   "outputs": [],
   "source": [
    "!bosh search fsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAufBfGU8AlJ"
   },
   "source": [
    "The `--exact` flag can be used to return descriptor names with the exact spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXMuRO8v8AlJ"
   },
   "outputs": [],
   "source": [
    "!bosh search fsl --exact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8j2ortZ8AlJ"
   },
   "source": [
    "#### BoSh example\n",
    "\n",
    "In order to be able to run a Boutiques tool, an invocation JSON file is required.\n",
    "Invocation files consist of the command parameters/inputs that need to be provided to run the tool.\n",
    "\n",
    "The `bosh example` command provides an example combination tool parameters in the expected JSON format\n",
    "\n",
    "Let's get an example invocation of fslstats (zenodo.4472771)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbYBxuMl8AlK"
   },
   "outputs": [],
   "source": [
    "!bosh example zenodo.4472771"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jK1m0X9i8AlL"
   },
   "source": [
    "To get additional optional parameter, the `--complete` flag can be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmtrJaKP8AlL"
   },
   "outputs": [],
   "source": [
    "!bosh example zenodo.4472771 --complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7R1Jx2858AlL"
   },
   "source": [
    "Today we'll use fslstats to calculate the histogram of one of the bigbrain blocks. We will do that in a new DataLad dataset so that we can publish it easily later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWwCiasZ8AlL"
   },
   "outputs": [],
   "source": [
    "%cd /content\n",
    "!datalad create histogram\n",
    "%cd histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're just missing the invocation file, so let's create it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu_BUqxd8AlM"
   },
   "outputs": [],
   "source": [
    "!echo '{\"input_file\": \"../conp-dataset/projects/BigBrain/3D_Volumes/MNI-ICBM152_Space/nii/full8_400um_2009b_sym.nii.gz\", \"h\": 10}' > invocation.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGsyQpfd8AlM"
   },
   "source": [
    "#### Launching tools with `bosh exec launch`\n",
    "\n",
    "Once we know which Boutiques tool we'd like to use and have created a valid invocation, we are ready to launch our tool.\n",
    "This can be achieved using the `bosh exec launch` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Caj08B2u8AlP"
   },
   "outputs": [],
   "source": [
    "!bosh exec launch zenodo.4472771 invocation.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution produced one file, a text file containing the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lmFuMuc8AlQ"
   },
   "outputs": [],
   "source": [
    "!mv ../conp-dataset/projects/BigBrain/3D_Volumes/MNI-ICBM152_Space/nii/full8_400um_2009b_sym.txt .\n",
    "!head full8_400um_2009b_sym.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's finally plot the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkVjApGX8AlR"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "hist_data = np.genfromtxt('full8_400um_2009b_sym.txt')\n",
    "plt.bar(np.arange(len(hist_data[:-1])), hist_data[:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CB72Bq8y8AlT"
   },
   "source": [
    "#### Other useful features\n",
    "\n",
    "- Boutiques provides a Python API to enable integration of Boutiques tools directly within Python code\n",
    "- Integrated into [CBRAIN](http://cbrain.ca/) to enable execution of tools\n",
    "- Interfaces with existing neuroimaging pipeline engines such as [Pydra](https://github.com/nipype/pydra) and [TIGR_PURR](https://github.com/TIGRLab/TIGR_PURR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBigjYl38AlT"
   },
   "source": [
    "<div id=\"adding\"/>\n",
    "\n",
    "### Adding derived data to DataLad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will publish our newly-created histogram text file as a new DataLad dataset on the [Open Science Framework](https://osf.io/), a research data archive.\n",
    "\n",
    "To publish our histogram text file as a new DataLad dataset, we first have to save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZgNEEHM8AlT"
   },
   "outputs": [],
   "source": [
    "!datalad save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The save command adds a new commit to the dataset containing the newly created text file. We will then declare an OSF \"sibling\" to our dataset, where we will later push our data. Although our dataset will be publicly accessible on OSF, this step requires an authentication token linked with the OSF account in which the dataset will be deposited (ask the to your instructor) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1oFUpBDu8AlT"
   },
   "outputs": [],
   "source": [
    "!OSF_TOKEN=<ask_your_instructor> datalad create-sibling-osf --title 'BigBrain histogram' \\\n",
    "  --mode exportonly \\\n",
    "  -s osf-export \\\n",
    "  --description \"This carefully acquired data will bring science forward\" \\\n",
    "  --public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the URL that was created for your dataset. Note that OSF datasets can also be configured to be private. \n",
    "\n",
    "We can finally push our dataset to OSF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFk-oGup8Alc"
   },
   "outputs": [],
   "source": [
    "!OSF_TOKEN=<ask_your_instructor> git-annex export HEAD --to osf-export-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZkSFoVCxPog"
   },
   "source": [
    "<div id=\"part2\"/>\n",
    "\n",
    "# Part II: CBRAIN, a web portal to process BigBrain datasets on HPC clusters\n",
    "\n",
    "CBRAIN is a web portal where you will be able to access the BigBrain dataset and to launch tools on it. No more command-line required! In this tutorial we will launch `fslstats` on the BigBrain 40$\\mu$m blocks.\n",
    "\n",
    "<a href=\"https://docs.google.com/presentation/d/1YXFlPkxiGzUyHpbSzpS8X5RviVaosW0vDI0aZ3UlhIE/edit?usp=sharing\"><img src=\"figures/cbrain.png\"/>\n",
    "    </a>\n",
    "\n",
    "Link to the tutorial slides: [https://docs.google.com/presentation/d/1YXFlPkxiGzUyHpbSzpS8X5RviVaosW0vDI0aZ3UlhIE/edit?usp=sharing](https://docs.google.com/presentation/d/1YXFlPkxiGzUyHpbSzpS8X5RviVaosW0vDI0aZ3UlhIE/edit?usp=sharing)\n",
    "\n",
    "CBRAIN portal: [https://portal.cbrain.mcgill.ca/session/new)](https://portal.cbrain.mcgill.ca/session/new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4XHngsB1s-b"
   },
   "source": [
    "## Accessing CBRAIN files with SFTP\n",
    "\n",
    "We will use SFTP from CBRAIN servers to download result files.\n",
    "\n",
    "Detailed documentation to interact with CBRAIN using sftp can be found [here](https://portal.cbrain.mcgill.ca/doc/manual/uploading.html).\n",
    "\n",
    "Let's first create a directory to retrieve our files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UM2VbPn88cng"
   },
   "outputs": [],
   "source": [
    "%cd /content\n",
    "%mkdir cbrain_outputs\n",
    "%cd cbrain_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command initiates an interactive sftp session with CBRAIN. Once the connection is established, You will have to type:\n",
    "- Your CBRAIN password, to authenticate\n",
    "- `get block*`, to download BigBrain blocks\n",
    "- `exit`, to end the session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CAejkpD8h_i"
   },
   "outputs": [],
   "source": [
    "!ptyrun sftp -o StrictHostKeyChecking=no -P 7500 YOUR_LOGIN@ace-cbrain-1.cbrain.mcgill.ca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files are now available on the local computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFo8ulePP5as"
   },
   "outputs": [],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We hope you enjoyed the session! Feel free to reach out to us for any additional information:\n",
    "    \n",
    "[Natacha Beck](mailto:natacha.beck@mcgill.ca), [Tristan Glatard](mailto:tristan.glatard@concordia.ca), [Valérie Hayot-Sasson](mailto:valeriehayot@gmail.com)\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "DataLad_Boutiques_tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
